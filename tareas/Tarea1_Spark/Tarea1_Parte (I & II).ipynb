{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e6f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import StringType\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "os.environ[\n",
    "    \"PYSPARK_SUBMIT_ARGS\"\n",
    "] = \"--packages org.apache.hadoop:hadoop-aws:3.2.2,io.delta:delta-core_2.12:1.1.0  pyspark-shell \"\n",
    "\n",
    "os.environ['MINIO_USERNAME'] = 'grupo-02'\n",
    "os.environ['MINIO_PASSWORD'] = '6HgSzdwj8eNpHcux'\n",
    "        \n",
    "config = {\n",
    "    \"spark.jars.packages\":\"org.apache.hadoop:hadoop-aws:3.2.2\",\n",
    "    \"spark.kubernetes.namespace\": \"spark\",\n",
    "    \"spark.kubernetes.container.image\": \"cronosnull/abd-spark-base:202301\",\n",
    "    \"spark.executor.instances\": \"17\",\n",
    "    \"spark.executor.memory\": \"7g\",\n",
    "    \"spark.executor.cores\": \"1\",\n",
    "    \"spark.driver.memory\":\"7g\",\n",
    "    \"spark.driver.port\":\"38889\",\n",
    "    \"spark.driver.blockManager.port\":\"7777\",\n",
    "    \"spark.driver.bindAddress\": \"0.0.0.0\",\n",
    "    \"spark.driver.host\": \"172.24.99.147\",\n",
    "    \"spark.kubernetes.executor.request.cores\":\"500m\",\n",
    "    \"spark.hadoop.fs.s3a.endpoint\": \"http://172.24.99.18:9000\",\n",
    "    # Credenciales de MinNIO, no olvide asignar las variables de entorno  \n",
    "    \"spark.hadoop.fs.s3a.access.key\": os.environ.get('MINIO_USERNAME', \"--\"),\n",
    "    \"spark.hadoop.fs.s3a.secret.key\": os.environ.get('MINIO_PASSWORD', \"--\"),\n",
    "    \"spark.hadoop.fs.s3a.path.style.access\": True,\n",
    "    \"spark.hadoop.fs.s3a.impl\": \"org.apache.hadoop.fs.s3a.S3AFileSystem\",\n",
    "    \"spark.hadoop.fs.s3a.aws.credentials.provider\": \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\",\n",
    "    \"spark.kubernetes.local.dirs.tmpfs\":True,\n",
    "\n",
    "}\n",
    "\n",
    "def get_spark_session(app_name: str, conf: SparkConf):\n",
    "    conf.setMaster(\"k8s://https://172.24.99.68:16443\")\n",
    "    for key, value in config.items():\n",
    "        conf.set(key, value)    \n",
    "        conf.set(\"spark.ui.port\",\"4040\")\n",
    "    return SparkSession.builder.appName(app_name).config(conf=conf).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f68db1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\r\n",
      "      ____              __\r\n",
      "     / __/__  ___ _____/ /__\r\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\r\n",
      "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.2.0\r\n",
      "      /_/\r\n",
      "                        \r\n",
      "Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 1.8.0_322\r\n",
      "Branch \r\n",
      "Compiled by user  on 2022-03-26T09:34:47Z\r\n",
      "Revision \r\n",
      "Url \r\n",
      "Type --help for more information.\r\n"
     ]
    }
   ],
   "source": [
    "!spark-submit --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "152f4c04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.24.99.147:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>k8s://https://172.24.99.68:16443</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>grupo-02-app-prueba</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd5df7e23d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = get_spark_session(\"grupo-02-app-prueba\", SparkConf())\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39c1d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if spark is not None:\n",
    "    print(\"La sesión de Spark se creó correctamente.\")\n",
    "else:\n",
    "    print(\"Ocurrió un error al crear la sesión de Spark.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c17d419",
   "metadata": {},
   "source": [
    "# Parte I\n",
    "\n",
    "## A (Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee37b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Lee el archivo JSON en un DataFrame de Spark\n",
    "df = spark.read.format(\"json\").option(\"header\", \"false\").load(\"s3a://noticias2016/individual_files/*.json.gz\")\n",
    "df.createOrReplaceTempView(\"noticias\")\n",
    "\n",
    "##STOPWORDS\n",
    "spStopWords = spark.read.text(\"s3a://user-data/grupo-02/stopwords/spanish\")\n",
    "spStopWords.createOrReplaceTempView(\"stopwords\")\n",
    "\n",
    "# Almacenar los datos en caché para mejorar el rendimiento de consultas repetidas\n",
    "df = df.repartition(200, \"title\").cache()\n",
    "\n",
    "# Ejecuta una consulta SQL en la vista temporal\n",
    "result = spark.sql(\"\"\"\n",
    "\n",
    "  WITH DATA AS (SELECT lower(A.word) AS title , 1 veces\n",
    "   FROM\n",
    "     (SELECT EXPLODE(SPLIT(title, ' ')) AS word\n",
    "      FROM noticias) A\n",
    "   LEFT JOIN stopwords B ON lower(B.value) = lower(A.word)\n",
    "   WHERE B.value IS NULL)\n",
    "   \n",
    "   SELECT  REGEXP_REPLACE(title, '[^0-9A-Za-z]' , '' ) title, sum(veces) veces\n",
    "   FROM DATA A\n",
    "   where REGEXP_REPLACE(title, '[^0-9A-Za-z]' , '' ) <>''\n",
    "   group by REGEXP_REPLACE(title, '[^0-9A-Za-z]' , '' )\n",
    "   order by 2 desc\n",
    "   \n",
    "   \n",
    "\"\"\")\n",
    "\n",
    "# Muestra las primeras 100 filas del resultado\n",
    "result.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e3cb7f",
   "metadata": {},
   "source": [
    "## B (Body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Lee el archivo JSON en un DataFrame de Spark\n",
    "df0 = spark.read.format(\"json\").option(\"header\", \"false\").load(\"s3a://noticias2016/individual_files/*.json.gz\")\n",
    "df0.createOrReplaceTempView(\"noticias\")\n",
    "\n",
    "##STOPWORDS\n",
    "spStopWords = spark.read.text(\"s3a://user-data/grupo-02/stopwords/spanish\")\n",
    "spStopWords.createOrReplaceTempView(\"stopwords\")\n",
    "\n",
    "# Almacenar los datos en caché para mejorar el rendimiento de consultas repetidas\n",
    "df0 = df0.repartition(200, \"text\").cache()\n",
    "\n",
    "# Ejecuta una consulta SQL en la vista temporal\n",
    "result = spark.sql(\"\"\"\n",
    "\n",
    "  WITH DATA AS (SELECT lower(A.text) AS text , 1 veces , b.value\n",
    "   FROM\n",
    "     (SELECT EXPLODE(SPLIT(text, ' ')) AS text\n",
    "      FROM noticias) A\n",
    "   LEFT JOIN stopwords B ON B.value = lower(A.text)\n",
    "   where B.value is null\n",
    "   \n",
    "   )\n",
    "   \n",
    "   \n",
    "   SELECT  \n",
    "   REGEXP_REPLACE(a.text, '[^0-9A-Za-z]' , '' ) text, \n",
    "   sum(a.veces) veces\n",
    "   \n",
    "   FROM DATA A\n",
    "   left join stopwords b on REGEXP_REPLACE(a.text, '[^0-9A-Za-z]' , '' ) = b.value\n",
    "   \n",
    "   where REGEXP_REPLACE(a.text, '[^0-9A-Za-z]' , '' ) <>''\n",
    "   and B.value is null\n",
    "   \n",
    "   group by \n",
    "   REGEXP_REPLACE(a.text, '[^0-9A-Za-z]' , '' )\n",
    "  \n",
    "   order by 2 desc\n",
    "   \n",
    "   \n",
    "\"\"\")\n",
    "\n",
    "# Muestra las primeras 100 filas del resultado\n",
    "result.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3feca37",
   "metadata": {},
   "source": [
    "# Parte II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1517b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import date_format\n",
    "\n",
    "\n",
    "# Quitar espacios en los nombres es las columnas\n",
    "def remove_space_in_names(df):\n",
    "    for col_name in df.columns:\n",
    "        new_col_name = col_name.replace(' ', '')\n",
    "        df = df.withColumnRenamed(col_name, new_col_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Cambiar los tipos de datos del dataframe\n",
    "# Falta Rate_Code, store_and_forward, mta_tax\n",
    "def change_name_and_data_type_G1(df):\n",
    "    \n",
    "    df = remove_space_in_names(df)\n",
    "\n",
    "    df = df.withColumnRenamed(\"vendor_name\", \"vendor_id\").withColumn(\"vendor_id\", col(\"vendor_id\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"Trip_Pickup_DateTime\", \"pickup_datetime\").withColumn(\"pickup_datetime\", to_timestamp(\"pickup_datetime\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    df = df.withColumnRenamed(\"Trip_Dropoff_DateTime\", \"dropoff_datetime\").withColumn(\"dropoff_datetime\", to_timestamp(\"dropoff_datetime\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    df = df.withColumnRenamed(\"Passenger_Count\", \"passenger_count\").withColumn(\"passenger_count\", col(\"passenger_count\").cast(\"integer\"))\n",
    "    df = df.withColumnRenamed(\"Trip_Distance\", \"trip_distance\").withColumn(\"trip_distance\", col(\"trip_distance\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"Start_Lon\", \"pickup_longitude\").withColumn(\"pickup_longitude\", col(\"pickup_longitude\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"Start_Lat\", \"pickup_latitude\").withColumn(\"pickup_latitude\", col(\"pickup_latitude\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"Rate_Code\", \"rate_code\").withColumn(\"rate_code\", col(\"rate_code\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"store_and_forward\", \"store_and_fwd_flag\").withColumn(\"store_and_fwd_flag\", col(\"store_and_fwd_flag\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"End_Lon\", \"dropoff_longitude\").withColumn(\"dropoff_longitude\", col(\"dropoff_longitude\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"End_Lat\", \"dropoff_latitude\").withColumn(\"dropoff_latitude\", col(\"dropoff_latitude\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"Payment_Type\", \"payment_type\").withColumn(\"payment_type\", col(\"payment_type\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"Fare_Amt\", \"fare_amount\").withColumn(\"fare_amount\", col(\"fare_amount\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"surcharge\", \"surcharge\").withColumn(\"surcharge\", col(\"surcharge\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"mta_tax\", \"mta_tax\").withColumn(\"mta_tax\", col(\"mta_tax\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"Tip_Amt\", \"tip_amount\").withColumn(\"tip_amount\", col(\"tip_amount\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"Tolls_Amt\", \"tolls_amount\").withColumn(\"tolls_amount\", col(\"tolls_amount\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"Total_Amt\", \"total_amount\").withColumn(\"total_amount\", col(\"total_amount\").cast(\"double\"))\n",
    "    \n",
    "    #Crear nueva columna\n",
    "    df= df.withColumn(\"date_travel\", date_format(\"pickup_datetime\", \"yyyy-MM-dd\").alias(\"date_travel\"))\n",
    "    df = df.withColumn(\"date_travel\", to_date(\"date_travel\", \"yyyy-MM-dd\"))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def change_name_and_data_type_G2(df):\n",
    "    \n",
    "    df = remove_space_in_names(df)\n",
    "\n",
    "    df = df.withColumnRenamed(\"vendor_id\", \"vendor_id\").withColumn(\"vendor_id\", col(\"vendor_id\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"pickup_datetime\", \"pickup_datetime\").withColumn(\"pickup_datetime\", to_timestamp(\"pickup_datetime\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    df = df.withColumnRenamed(\"dropoff_datetime\", \"dropoff_datetime\").withColumn(\"dropoff_datetime\", to_timestamp(\"dropoff_datetime\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    df = df.withColumnRenamed(\"passenger_count\", \"passenger_count\").withColumn(\"passenger_count\", col(\"passenger_count\").cast(\"integer\"))\n",
    "    df = df.withColumnRenamed(\"trip_distance\", \"trip_distance\").withColumn(\"trip_distance\", col(\"trip_distance\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"pickup_longitude\", \"pickup_longitude\").withColumn(\"pickup_longitude\", col(\"pickup_longitude\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"pickup_latitude\", \"pickup_latitude\").withColumn(\"pickup_latitude\", col(\"pickup_latitude\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"rate_code\", \"rate_code\").withColumn(\"rate_code\", col(\"rate_code\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"store_and_fwd_flag\", \"store_and_fwd_flag\").withColumn(\"store_and_fwd_flag\", col(\"store_and_fwd_flag\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"dropoff_longitude\", \"dropoff_longitude\").withColumn(\"dropoff_longitude\", col(\"dropoff_longitude\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"dropoff_latitude\", \"dropoff_latitude\").withColumn(\"dropoff_latitude\", col(\"dropoff_latitude\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"payment_type\", \"payment_type\").withColumn(\"payment_type\", col(\"payment_type\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"fare_amount\", \"fare_amount\").withColumn(\"fare_amount\", col(\"fare_amount\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"surcharge\", \"surcharge\").withColumn(\"surcharge\", col(\"surcharge\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"mta_tax\", \"mta_tax\").withColumn(\"mta_tax\", col(\"mta_tax\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"tip_amount\", \"tip_amount\").withColumn(\"tip_amount\", col(\"tip_amount\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"tolls_amount\", \"tolls_amount\").withColumn(\"tolls_amount\", col(\"tolls_amount\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"total_amount\", \"total_amount\").withColumn(\"total_amount\", col(\"total_amount\").cast(\"double\"))\n",
    "    \n",
    "   \n",
    "#     #Crear nueva columna\n",
    "    df= df.withColumn(\"date_travel\", date_format(\"pickup_datetime\", \"yyyy-MM-dd\").alias(\"date_travel\"))\n",
    "    df = df.withColumn(\"date_travel\", to_date(\"date_travel\", \"yyyy-MM-dd\"))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def change_name_and_data_type_G3(df):\n",
    "    \n",
    "    df = remove_space_in_names(df)\n",
    "\n",
    "    df = df.withColumnRenamed(\"VendorID\", \"vendor_id\").withColumn(\"vendor_id\", col(\"vendor_id\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"tpep_pickup_datetime\", \"pickup_datetime\").withColumn(\"pickup_datetime\", to_timestamp(\"pickup_datetime\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    df = df.withColumnRenamed(\"tpep_dropoff_datetime\", \"dropoff_datetime\").withColumn(\"dropoff_datetime\", to_timestamp(\"dropoff_datetime\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    df = df.withColumnRenamed(\"passenger_count\", \"passenger_count\").withColumn(\"passenger_count\", col(\"passenger_count\").cast(\"integer\"))\n",
    "    df = df.withColumnRenamed(\"trip_distance\", \"trip_distance\").withColumn(\"trip_distance\", col(\"trip_distance\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"pickup_longitude\", \"pickup_longitude\").withColumn(\"pickup_longitude\", col(\"pickup_longitude\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"pickup_latitude\", \"pickup_latitude\").withColumn(\"pickup_latitude\", col(\"pickup_latitude\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"RateCodeID\", \"rate_code\").withColumn(\"rate_code\", col(\"rate_code\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"store_and_fwd_flag\", \"store_and_fwd_flag\").withColumn(\"store_and_fwd_flag\", col(\"store_and_fwd_flag\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"dropoff_longitude\", \"dropoff_longitude\").withColumn(\"dropoff_longitude\", col(\"dropoff_longitude\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"dropoff_latitude\", \"dropoff_latitude\").withColumn(\"dropoff_latitude\", col(\"dropoff_latitude\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"payment_type\", \"payment_type\").withColumn(\"payment_type\", col(\"payment_type\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"fare_amount\", \"fare_amount\").withColumn(\"fare_amount\", col(\"fare_amount\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"improvement_surcharge\", \"surcharge\").withColumn(\"surcharge\", col(\"surcharge\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"mta_tax\", \"mta_tax\").withColumn(\"mta_tax\", col(\"mta_tax\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"tip_amount\", \"tip_amount\").withColumn(\"tip_amount\", col(\"tip_amount\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"tolls_amount\", \"tolls_amount\").withColumn(\"tolls_amount\", col(\"tolls_amount\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"total_amount\", \"total_amount\").withColumn(\"total_amount\", col(\"total_amount\").cast(\"double\"))\n",
    "   \n",
    "    #Eliminar columna no usada\n",
    "    df = df.drop(\"extra\")\n",
    "    \n",
    "   \n",
    "    #Crear nueva columna\n",
    "    df= df.withColumn(\"date_travel\", date_format(\"pickup_datetime\", \"yyyy-MM-dd\").alias(\"date_travel\"))\n",
    "    df = df.withColumn(\"date_travel\", to_date(\"date_travel\", \"yyyy-MM-dd\"))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def change_name_and_data_type_G4(df):\n",
    "    \n",
    "    df = remove_space_in_names(df)\n",
    "\n",
    "    df = df.withColumnRenamed(\"VendorID\", \"vendor_id\").withColumn(\"vendor_id\", col(\"vendor_id\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"tpep_pickup_datetime\", \"pickup_datetime\").withColumn(\"pickup_datetime\", to_timestamp(\"pickup_datetime\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    df = df.withColumnRenamed(\"tpep_dropoff_datetime\", \"dropoff_datetime\").withColumn(\"dropoff_datetime\", to_timestamp(\"dropoff_datetime\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    df = df.withColumnRenamed(\"passenger_count\", \"passenger_count\").withColumn(\"passenger_count\", col(\"passenger_count\").cast(\"integer\"))\n",
    "    df = df.withColumnRenamed(\"trip_distance\", \"trip_distance\").withColumn(\"trip_distance\", col(\"trip_distance\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"RateCodeID\", \"rate_code\").withColumn(\"rate_code\", col(\"rate_code\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"store_and_fwd_flag\", \"store_and_fwd_flag\").withColumn(\"store_and_fwd_flag\", col(\"store_and_fwd_flag\").cast(\"string\"))\n",
    "    df = df.withColumn(\"PULocationID\", col(\"PULocationID\").cast(\"integer\"))\n",
    "    df = df.withColumn(\"PULocationID\", col(\"PULocationID\").cast(\"integer\"))\n",
    "    \n",
    "#     df = df.withColumnRenamed(\"PULocationID\", \"pickup_zone\").withColumn(\"pickup_zone\", col(\"pickup_zone\").cast(\"string\"))\n",
    "#     df = df.withColumnRenamed(\"PULocationID\", \"dropoff_zone\").withColumn(\"pickup_zone\", col(\"pickup_zone\").cast(\"string\"))\n",
    "\n",
    "    df = df.withColumnRenamed(\"payment_type\", \"payment_type\").withColumn(\"payment_type\", col(\"payment_type\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"fare_amount\", \"fare_amount\").withColumn(\"fare_amount\", col(\"fare_amount\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"improvement_surcharge\", \"surcharge\").withColumn(\"surcharge\", col(\"surcharge\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"mta_tax\", \"mta_tax\").withColumn(\"mta_tax\", col(\"mta_tax\").cast(\"string\"))\n",
    "    df = df.withColumnRenamed(\"tip_amount\", \"tip_amount\").withColumn(\"tip_amount\", col(\"tip_amount\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"tolls_amount\", \"tolls_amount\").withColumn(\"tolls_amount\", col(\"tolls_amount\").cast(\"double\"))\n",
    "    df = df.withColumnRenamed(\"total_amount\", \"total_amount\").withColumn(\"total_amount\", col(\"total_amount\").cast(\"double\"))\n",
    "    \n",
    "    #Eliminar columna no usada\n",
    "    df = df.drop(\"extra\")\n",
    "    \n",
    "    #Crear nueva columna\n",
    "    df= df.withColumn(\"date_travel\", date_format(\"pickup_datetime\", \"yyyy-MM-dd\").alias(\"date_travel\"))\n",
    "    df = df.withColumn(\"date_travel\", to_date(\"date_travel\", \"yyyy-MM-dd\"))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656abaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# charge info group 1\n",
    "df_taxis_G1 = spark.read.csv(\"s3a://taxis/yellow_tripdata_2009-*.csv.gz\", header=True)\n",
    "df_taxis_G1_change_type = change_name_and_data_type_G1(df_taxis_G1)\n",
    "\n",
    "df_taxis_G1_change_type.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443c691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# charge info group 2\n",
    "\n",
    "df_taxis_G2_2010 = spark.read.csv(\"s3a://taxis/yellow_tripdata_2010-*.csv.gz\", header=True)\n",
    "df_taxis_G2_2010_change_type = change_name_and_data_type_G2(df_taxis_G2_2010)\n",
    "\n",
    "df_taxis_G2_2011 = spark.read.csv(\"s3a://taxis/yellow_tripdata_2011-*.csv.gz\", header=True)\n",
    "df_taxis_G2_2011_change_type = change_name_and_data_type_G2(df_taxis_G2_2011)\n",
    "\n",
    "df_taxis_G2_2012 = spark.read.csv(\"s3a://taxis/yellow_tripdata_2012-*.csv.gz\", header=True)\n",
    "df_taxis_G2_2012_change_type = change_name_and_data_type_G2(df_taxis_G2_2012)\n",
    "\n",
    "df_taxis_G2_2013 = spark.read.csv(\"s3a://taxis/yellow_tripdata_2013-*.csv.gz\", header=True)\n",
    "df_taxis_G2_2013_change_type = change_name_and_data_type_G2(df_taxis_G2_2013)\n",
    "\n",
    "df_taxis_G2_2014 = spark.read.csv(\"s3a://taxis/yellow_tripdata_2014-*.csv.gz\", header=True)\n",
    "df_taxis_G2_2014_change_type = change_name_and_data_type_G2(df_taxis_G2_2014)\n",
    "\n",
    "\n",
    "df_taxis_G2_change_type = df_taxis_G2_2010_change_type.unionAll(df_taxis_G2_2011_change_type).unionAll(df_taxis_G2_2013_change_type).unionAll(df_taxis_G2_2014_change_type)\n",
    "\n",
    "df_taxis_G1_change_type.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c84c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# charge info group 3\n",
    "\n",
    "df_taxis_G3_2015 = spark.read.csv(\"s3a://taxis/yellow_tripdata_2015-*.csv.gz\", header=True)\n",
    "df_taxis_G3_2015_change_type = change_name_and_data_type_G3(df_taxis_G3_2015)\n",
    "\n",
    "df_taxis_G3_2016 = spark.read.csv(\"s3a://taxis/yellow_tripdata_2016-*.csv.gz\", header=True)\n",
    "df_taxis_G3_2016_change_type = change_name_and_data_type_G3(df_taxis_G3_2016)\n",
    "\n",
    "df_taxis_G3_change_type = df_taxis_G3_2015_change_type.unionAll(df_taxis_G3_2016_change_type)\n",
    "\n",
    "df_taxis_G3_change_type.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf14d40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# charge info group 4\n",
    "\n",
    "df_taxis_G4_2017 = spark.read.csv(\"s3a://taxis/yellow_tripdata_2017-*.csv.gz\", header=True)\n",
    "df_taxis_G4_2017_change_type = change_name_and_data_type_G4(df_taxis_G4_2017)\n",
    "\n",
    "df_taxis_G4_2018 = spark.read.csv(\"s3a://taxis/yellow_tripdata_2018-*.csv.gz\", header=True)\n",
    "df_taxis_G4_2018_change_type = change_name_and_data_type_G4(df_taxis_G4_2018)\n",
    "\n",
    "df_taxis_G4_2019 = spark.read.csv(\"s3a://taxis/yellow_tripdata_2019-*.csv.gz\", header=True)\n",
    "df_taxis_G4_2019 = df_taxis_G4_2019.drop(\"congestion_surcharge\")\n",
    "df_taxis_G4_2019_change_type = change_name_and_data_type_G4(df_taxis_G4_2019)\n",
    "\n",
    "\n",
    "df_taxis_G4_change_type = df_taxis_G4_2017_change_type.unionAll(df_taxis_G4_2018_change_type).unionAll(df_taxis_G4_2019_change_type)\n",
    "\n",
    "df_taxis_G4_change_type.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8281e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the zone name\n",
    "df_taxis_G4_change_type_2 = df_taxis_G4_change_type\n",
    "\n",
    "df_location_id = spark.read.csv(\"s3a://user-data/grupo-02/taxi+_zone_lookup.csv\", header=True)\n",
    "\n",
    "df_location_id.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e784c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the zone to the dataframe 4 \n",
    "df_taxis_G4_change_type_2 = df_taxis_G4_change_type\n",
    "\n",
    "df_taxis_G4_change_type_2 = df_taxis_G4_change_type_2.join(df_location_id, df_taxis_G4_change_type_2.PULocationID == df_location_id.LocationID).select(df_taxis_G4_change_type_2['*'], df_location_id['Zone'])\n",
    "df_taxis_G4_change_type_2 = df_taxis_G4_change_type_2.withColumnRenamed(\"Zone\", \"pickup_zone\")\n",
    "\n",
    "df_taxis_G4_change_type_2 = df_taxis_G4_change_type_2.alias('a').join(df_location_id.alias('b'), df_taxis_G4_change_type_2.alias('a').DOLocationID == df_location_id.alias('b').LocationID).select('a.*','b.Zone')\n",
    "df_taxis_G4_change_type_2 = df_taxis_G4_change_type_2.withColumnRenamed(\"Zone\", \"dropoff_zone\")\n",
    "    \n",
    "df_taxis_G4_change_type_2 = df_taxis_G4_change_type_2.drop('DOLocationID','PULocationID')\n",
    "df_taxis_G4_change_type_2.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49126479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all the data with latitude and longitud\n",
    "\n",
    "df_taxis_with_lat_lon = df_taxis_G1_change_type.unionAll(df_taxis_G2_change_type).unionAll(df_taxis_G3_change_type)\n",
    "\n",
    "df_taxis_with_lat_lon.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa266af",
   "metadata": {},
   "source": [
    "# geo pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a1bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, shape\n",
    "from shapely import wkb, wkt\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DoubleType,DecimalType\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "import shapely.speedups\n",
    "shapely.speedups.enable() # this makes some spatial queries run faster\n",
    "\n",
    "#Load the data \n",
    "df_taxi_zones_csv = spark.read.csv(\"s3a://user-data/grupo-02/taxi_zones.csv\", header=True)\n",
    "df_taxi_zones_csv.printSchema()\n",
    "\n",
    "# define a function to convert a WKT string to a Shapely geometry object\n",
    "def wkt_to_geometry(wkt_str):\n",
    "    return wkt.loads(wkt_str)\n",
    "\n",
    "# read in the CSV file and convert the 'the_geom' column to a geometry data type\n",
    "df_taxi_zones_csv = pd.read_csv(\"taxi_zones.csv\", dtype={'the_geom': 'str'}).assign(the_geom=lambda x: x['the_geom'].apply(wkt_to_geometry))\n",
    "\n",
    "# print the data types of the columns\n",
    "print(df_taxi_zones_csv.dtypes)\n",
    "\n",
    "gdf  = gpd.GeoDataFrame(df_taxi_zones_csv, geometry='the_geom')\n",
    "\n",
    "# spark.broadcast(gdf)\n",
    "\n",
    "def find_zone(latitude, longitude): \n",
    "    mgdf = gdf.apply(lambda x: x['zone'] if x['the_geom'].intersects(Point(longitude,latitude)) else None, axis=1)\n",
    "    idx = mgdf.first_valid_index()\n",
    "    first_valid_value = mgdf.loc[idx] if idx is not None else None\n",
    "    return first_valid_value\n",
    "\n",
    "\n",
    "\n",
    "find_zone_udf = udf(lambda lat, lon: find_zone(lat, lon), StringType())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2466a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_taxis_with_lat_lon= df_taxis_with_lat_lon.withColumn(\"pickup_zone\", find_zone_udf(col(\"pickup_latitude\"),col(\"pickup_longitude\")))\n",
    "\n",
    "df_taxis_with_lat_lon= df_taxis_with_lat_lon.withColumn(\"dropoff_zone\", find_zone_udf(col(\"dropoff_latitude\"),col(\"dropoff_longitude\")))\n",
    "\n",
    "df_taxis_with_lat_lon = df_taxis_with_lat_lon.drop('pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude')\n",
    "df_taxis_with_lat_lon.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cabdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all the data\n",
    "\n",
    "final_df_taxi_zones  = df_taxis_with_lat_lon.unionAll(df_taxis_G4_change_type_2)\n",
    "\n",
    "final_df_taxi_zones= final_df_taxi_zones.withColumn(\"year_travel\", date_format(\"pickup_datetime\", \"yyyy\").alias(\"year_travel\"))\n",
    "final_df_taxi_zones= final_df_taxi_zones.withColumn(\"month_travel\", date_format(\"pickup_datetime\", \"MM\").alias(\"month_travel\"))\n",
    "final_df_taxi_zones= final_df_taxi_zones.withColumn(\"day_travel\", date_format(\"pickup_datetime\", \"dd\").alias(\"day_travel\"))\n",
    "\n",
    "\n",
    "final_df_taxi_zones = final_df_taxi_zones.withColumn(\"year_travel\", col(\"year_travel\").cast(\"integer\"))\n",
    "final_df_taxi_zones = final_df_taxi_zones.withColumn(\"month_travel\", col(\"year_travel\").cast(\"integer\"))\n",
    "final_df_taxi_zones = final_df_taxi_zones.withColumn(\"day_travel\", col(\"year_travel\").cast(\"integer\"))\n",
    "\n",
    "\n",
    "final_df_taxi_zones.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un dataframe para analizar los datos\n",
    "\n",
    "pd_df_final_df_taxi_zones = final_df_taxi_zones.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afadf591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se sube el CSV a Minio\n",
    "\n",
    "final_df_taxi_zones.write.mode(\"overwrite\").csv(\"s3a://user-data/grupo-02/prueba/prueba.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572a0e1d",
   "metadata": {},
   "source": [
    "# Analisis de los datos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fc4083",
   "metadata": {},
   "source": [
    "## punto G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2542c315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+-----+\n",
      "|year|         pickup_zone|        dropoff_zone|count|\n",
      "+----+--------------------+--------------------+-----+\n",
      "|2009|                null|                null|    4|\n",
      "|2009|Upper East Side S...|Upper East Side S...|    3|\n",
      "|2009|      Yorkville West|Upper East Side S...|    2|\n",
      "|2009|Upper West Side N...|Upper West Side N...|    2|\n",
      "|2009|Upper East Side S...|Upper East Side N...|    2|\n",
      "|2009|      Midtown Center|      Midtown Center|    2|\n",
      "|2009|Long Island City/...|Long Island City/...|    2|\n",
      "|2009|Upper West Side S...|      Yorkville East|    2|\n",
      "|2009|        Central Park| Lincoln Square East|    2|\n",
      "|2009|      Midtown Center|       Midtown North|    2|\n",
      "+----+--------------------+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>pickup_zone</th>\n",
       "      <th>dropoff_zone</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>Upper East Side South</td>\n",
       "      <td>Upper East Side South</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>Upper East Side South</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>Midtown Center</td>\n",
       "      <td>Midtown Center</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>Long Island City/Queens Plaza</td>\n",
       "      <td>Long Island City/Queens Plaza</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                    pickup_zone                   dropoff_zone  count\n",
       "0  2009                           None                           None      4\n",
       "1  2009          Upper East Side South          Upper East Side South      3\n",
       "2  2009                 Yorkville West          Upper East Side South      2\n",
       "3  2009                 Midtown Center                 Midtown Center      2\n",
       "4  2009  Long Island City/Queens Plaza  Long Island City/Queens Plaza      2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "data = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"s3a://user-data/grupo-02/final_df_taxi_zones_test.csv\")\n",
    "\n",
    "# Seleccionar columnas necesarias\n",
    "data = data.select(\"pickup_zone\", \"dropoff_zone\", \"year_travel\")\n",
    "\n",
    "# Agrupar por año, zona de origen y zona de entrega y hacer el conteo\n",
    "grouped_data = data.groupBy(year(\"year_travel\").alias(\"year\"), \"pickup_zone\", \"dropoff_zone\").count()\n",
    "\n",
    "# Ordenar por año y conteo de manera descendente\n",
    "sorted_data = grouped_data.orderBy(\"year\", \"count\", ascending=[True, False])\n",
    "\n",
    "# Mostrar los primeros 10 registros\n",
    "sorted_data.show(10)\n",
    "\n",
    "# Convertir a pandas y mostrar los primeros 5 registros\n",
    "sorted_data.limit(5).toPandas().head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434253c",
   "metadata": {},
   "source": [
    "## pivoteo de dropoff_zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9788e0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+------------+-----------------+----------------+------------+--------------+------------+---------+------------+------------+------------+-----------------+------------+------------------------+--------+------------+----------------+--------+-----------------------+-----------------------+---------+-----------+--------+-----------------+---------------+---------------+-------------------+-------------------+-------------------+-----------------------------+---------------+-----------------------------+--------------+------------+-------------+-------------+-------------------+-----------+----------------------------+-----------------------+-----------------------------+-------------------------+--------------------+--------+---------------------+---------------------+---------------------+---------------------+-------------------------+------------+------------------+--------------+--------------+\n",
      "| dropoff_zone|null|Battery Park|Battery Park City|Bensonhurst East|Bloomingdale|Central Harlem|Central Park|Chinatown|Clinton East|Clinton West|East Chelsea|East Harlem South|East Village|Financial District North|Flatiron|Forest Hills|Garment District|Gramercy|Greenwich Village North|Greenwich Village South|Hudson Sq|JFK Airport|Kips Bay|LaGuardia Airport|Lenox Hill East|Lenox Hill West|Lincoln Square East|Lincoln Square West|Little Italy/NoLiTa|Long Island City/Queens Plaza|Lower East Side|Meatpacking/West Village West|Midtown Center|Midtown East|Midtown North|Midtown South|Morningside Heights|Murray Hill|Penn Station/Madison Sq West|Queensbridge/Ravenswood|Sutton Place/Turtle Bay North|Times Sq/Theatre District|TriBeCa/Civic Center|Union Sq|Upper East Side North|Upper East Side South|Upper West Side North|Upper West Side South|West Chelsea/Hudson Yards|West Village|World Trade Center|Yorkville East|Yorkville West|\n",
      "+-------------+----+------------+-----------------+----------------+------------+--------------+------------+---------+------------+------------+------------+-----------------+------------+------------------------+--------+------------+----------------+--------+-----------------------+-----------------------+---------+-----------+--------+-----------------+---------------+---------------+-------------------+-------------------+-------------------+-----------------------------+---------------+-----------------------------+--------------+------------+-------------+-------------+-------------------+-----------+----------------------------+-----------------------+-----------------------------+-------------------------+--------------------+--------+---------------------+---------------------+---------------------+---------------------+-------------------------+------------+------------------+--------------+--------------+\n",
      "|         null|   4|           0|                0|               0|           0|             0|           0|        0|           0|           0|           0|                0|           0|                       0|       0|           0|               0|       0|                      0|                      0|        0|          0|       0|                0|              0|              0|                  0|                  0|                  0|                            0|              0|                            0|             0|           0|            0|            0|                  0|          0|                           0|                      0|                            0|                        0|                   0|       0|                    0|                    0|                    0|                    0|                        0|           0|                 0|             0|             0|\n",
      "|Alphabet City|   0|           0|                0|               0|           0|             0|           0|        0|           0|           0|           0|                0|           0|                       0|       0|           0|               0|       0|                      0|                      0|        0|          0|       0|                0|              0|              0|                  0|                  0|                  0|                            0|              1|                            0|             0|           0|            0|            0|                  0|          0|                           0|                      0|                            0|                        0|                   0|       0|                    0|                    0|                    0|                    0|                        0|           0|                 0|             0|             0|\n",
      "+-------------+----+------------+-----------------+----------------+------------+--------------+------------+---------+------------+------------+------------+-----------------+------------+------------------------+--------+------------+----------------+--------+-----------------------+-----------------------+---------+-----------+--------+-----------------+---------------+---------------+-------------------+-------------------+-------------------+-----------------------------+---------------+-----------------------------+--------------+------------+-------------+-------------+-------------------+-----------+----------------------------+-----------------------+-----------------------------+-------------------------+--------------------+--------+---------------------+---------------------+---------------------+---------------------+-------------------------+------------+------------------+--------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "# Leer la tabla\n",
    "data = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"s3a://user-data/grupo-02/final_df_taxi_zones_test.csv\")\n",
    "\n",
    "# Seleccionar columnas necesarias y agrupar\n",
    "grouped_data = data.select(\"pickup_zone\", \"dropoff_zone\", \"year_travel\").groupBy(year(\"year_travel\").alias(\"year\"), \"pickup_zone\", \"dropoff_zone\").count()\n",
    "\n",
    "# Generar la matriz\n",
    "pivoted_data = grouped_data.groupBy(\"dropoff_zone\").pivot(\"pickup_zone\").sum(\"count\")\n",
    "\n",
    "# Ordenar la matriz y mostrar los primeros 10 registros\n",
    "sorted_data = pivoted_data.orderBy(\"dropoff_zone\", ascending=True).na.fill(0)\n",
    "sorted_data.show(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b35ea5",
   "metadata": {},
   "source": [
    "## pivoteo con pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd5806e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        pickup_zone  null  Alphabet City  Astoria  Central Park  \\\n",
      "0  2009                  0   4.0            0.0      0.0           0.0   \n",
      "1  2009       Battery Park   0.0            0.0      0.0           0.0   \n",
      "2  2009  Battery Park City   0.0            0.0      0.0           0.0   \n",
      "3  2009   Bensonhurst East   0.0            0.0      0.0           0.0   \n",
      "4  2009       Bloomingdale   0.0            0.0      0.0           0.0   \n",
      "\n",
      "   Clinton East  Clinton West  Coney Island  DUMBO/Vinegar Hill  ...  \\\n",
      "0           0.0           0.0           0.0                 0.0  ...   \n",
      "1           0.0           0.0           0.0                 0.0  ...   \n",
      "2           0.0           0.0           0.0                 1.0  ...   \n",
      "3           0.0           0.0           0.0                 0.0  ...   \n",
      "4           0.0           0.0           0.0                 0.0  ...   \n",
      "\n",
      "   Union Sq  Upper East Side North  Upper East Side South  \\\n",
      "0       0.0                    0.0                    0.0   \n",
      "1       0.0                    0.0                    0.0   \n",
      "2       0.0                    0.0                    0.0   \n",
      "3       0.0                    0.0                    0.0   \n",
      "4       0.0                    1.0                    0.0   \n",
      "\n",
      "   Upper West Side North  Upper West Side South  Washington Heights South  \\\n",
      "0                    1.0                    0.0                       0.0   \n",
      "1                    0.0                    0.0                       0.0   \n",
      "2                    0.0                    0.0                       0.0   \n",
      "3                    0.0                    0.0                       0.0   \n",
      "4                    0.0                    0.0                       0.0   \n",
      "\n",
      "   West Village  Williamsburg (South Side)  World Trade Center  Yorkville East  \n",
      "0           0.0                        0.0                 0.0             0.0  \n",
      "1           0.0                        0.0                 0.0             0.0  \n",
      "2           0.0                        0.0                 0.0             0.0  \n",
      "3           0.0                        0.0                 0.0             0.0  \n",
      "4           0.0                        0.0                 0.0             0.0  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "import pandas as pd\n",
    "\n",
    "data = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"s3a://user-data/grupo-02/final_df_taxi_zones_test.csv\")\n",
    "\n",
    "# Seleccionar columnas necesarias\n",
    "data = data.select(\"pickup_zone\", \"dropoff_zone\", \"year_travel\")\n",
    "\n",
    "# Agrupar por año, zona de origen y zona de entrega y hacer el conteo\n",
    "grouped_data = data.groupBy(year(\"year_travel\").alias(\"year\"), \"pickup_zone\")\\\n",
    "                   .pivot(\"dropoff_zone\")\\\n",
    "                   .count()\n",
    "\n",
    "# Ordenar por año y zona de origen\n",
    "sorted_data = grouped_data.orderBy(\"year\", \"pickup_zone\")\n",
    "\n",
    "# Mostrar los primeros 10 registros  ----sorted_data.show(10)\n",
    "\n",
    "# Convertir a pandas y mostrar los primeros 5 registros\n",
    "sorted_data.limit(5).toPandas().head(5)\n",
    "\n",
    "# Convertir a pandas\n",
    "pandas_data = sorted_data.toPandas()\n",
    "pandas_data.iloc[:1, :1]\n",
    "\n",
    "pandas_data = sorted_data.toPandas().fillna(value=0)\n",
    "\n",
    "\n",
    "# Mostrar los primeros 5 registros\n",
    "print(pandas_data.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb40381c",
   "metadata": {},
   "source": [
    "## instalacion matplolib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43762cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e45010d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fe2e0f8d3467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maltair\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotnine\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import bokeh.plotting as bop\n",
    "import altair as al\n",
    "import plotnine as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc59c7b5",
   "metadata": {},
   "source": [
    "## grafica Matriz de calor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c486c8cc",
   "metadata": {},
   "source": [
    "como la instalacion e importacion de matplotlib no fue posible por error en versionamiento no fue posible graficar la matriz de calor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b072fda",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fe14370f9429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Leer la tabla\n",
    "data = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"s3a://user-data/grupo-02/final_df_taxi_zones_test.csv\")\n",
    "\n",
    "\n",
    "# seleccionar datos de interés\n",
    "data = sorted_data.select(\"pickup_zone\", \"dropoff_zone\", \"year\", \"count\")\n",
    "\n",
    "# crear matriz pivot\n",
    "matrix = data.groupBy(\"pickup_zone\").pivot(\"dropoff_zone\").sum(\"count\").na.fill(0).orderBy(\"pickup_zone\").toPandas().values[:,1:]\n",
    "\n",
    "# crear figura y gráfico de matriz de calor\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(matrix)\n",
    "\n",
    "# ajustar etiquetas y títulos\n",
    "ax.set_xticks(np.arange(len(sorted_data.select(\"dropoff_zone\").distinct().collect())))\n",
    "ax.set_yticks(np.arange(len(sorted_data.select(\"pickup_zone\").distinct().collect())))\n",
    "ax.set_xticklabels(sorted_data.select(\"dropoff_zone\").distinct().rdd.map(lambda x: x[0]).collect())\n",
    "ax.set_yticklabels(sorted_data.select(\"pickup_zone\").distinct().rdd.map(lambda x: x[0]).collect())\n",
    "ax.set_xlabel('dropoff_zone')\n",
    "ax.set_ylabel('pickup_zone')\n",
    "ax.set_title('Matriz de calor')\n",
    "\n",
    "# agregar barras de color\n",
    "cbar = ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "# mostrar gráfico\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b1de1",
   "metadata": {},
   "source": [
    "## punto H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d909506",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular_destinations_per_years = pd_df_final_df_taxi_zones.groupby(['year_travel', 'dropoff_zone']).size().reset_index(name='count')\n",
    "\n",
    "most_popular_destinations_per_years = most_popular_destinations_per_years.sort_values(['year_travel', 'count'], ascending=[False, False])\n",
    "\n",
    "most_popular_destinations_per_years\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6cba38",
   "metadata": {},
   "source": [
    "## punto i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bbfd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_km_per_year = pd_df_final_df_taxi_zones.groupby(['year_travel'])['trip_distance'].sum()\n",
    "\n",
    "df_km_per_year = df_km_per_year.to_frame().reset_index()\n",
    "\n",
    "df_km_per_year[\"trip_distance_km\"] = df_km_per_year[\"trip_distance\"] * 1.609344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb15857",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_km_per_year[\"year_travel\"], df_km_per_year[\"trip_distance_km\"], '-o')\n",
    "\n",
    "\n",
    "plt.xlabel('Año')\n",
    "plt.xlim(2007, 2020)\n",
    "\n",
    "plt.ylabel('Distancia total recorrida en Kilometros ')\n",
    "\n",
    "plt.title(' Distancia total recorrida en Kilometros por año')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32614e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
